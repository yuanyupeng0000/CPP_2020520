{"iter_size": 1, "temporal_stride": 2, "validate": 5, "annotation_path": "/soft/yyp/openvino_training_extensions/pytorch_toolkit/action_recognition/data/UCF-101/UCF101_Action_detection_splits/ucf101_01.json", "sample_duration": 16, "cuda": true, "root_path": "data/UCF-101", "wide_resnet_k": 2, "try_resume": true, "arch": "resnet34_vtn", "nesterov": true, "weight_decay": 0.0001, "dataset_config": null, "batch_size": 64, "momentum": 0.9, "weighted_sampling": false, "learning_rate": 0.1, "initial_scale": 1.0, "resume_path": null, "tta": false, "scales": [1.0, 0.8408964152537145, 0.7071067811865475, 0.5946035575013604], "hidden_size": 512, "flow_path": null, "n_scales": 4, "fp16": false, "result_path": "logs/1", "scheduler": "plateau", "n_val_clips": 3, "train": false, "n_epochs": 200, "encoder": "resnet34", "layer_norm": true, "std_norm": true, "mean_norm": true, "n_classes": 101, "split": 1, "scale_step": 0.8408964152537145, "bidirectional_lstm": false, "checkpoint": 5, "teacher_checkpoint": null, "dampening": 0.9, "n_threads": 12, "teacher_model": null, "test": true, "drop_last": true, "rgb_path": null, "resume_train": true, "model": "resnet34_vtn", "video_format": "frames", "manual_seed": 1, "n_finetune_classes": null, "lr_step_size": 10, "begin_epoch": 1, "lr_patience": 10, "test_subset": "val", "crop_position_in_test": "c", "sample_size": 224, "scale_in_test": 1.0, "resnet_shortcut": "B", "norm_value": 255, "video_path": "/soft/yyp/openvino_training_extensions/pytorch_toolkit/action_recognition/data/UCF-101/frame_data", "model_depth": 18, "motion_path": null, "softmax_in_test": false, "n_test_clips": 10, "sync_bn": false, "onnx": null, "optimizer": "adam", "resnext_cardinality": 32, "pretrain_path": "data/UCF-101/model/resnet_34_vtn_rgb_ucf101_s1.pth", "hflip": true, "gamma": 0.1, "mean_dataset": "imagenet", "dataset": "ucf101", "val": false, "gradient_clipping": null}