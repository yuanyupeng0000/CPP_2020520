layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 256
      dim: 56
      dim: 56
    }
  }
}
layer {
  name: "resx1_conv1"
  type: "Convolution"
  bottom: "data"
  top: "resx1_conv1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -12
    scale: 1.813458
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.3138955
  }
}
layer {
  name: "resx1_conv1_bn"
  type: "BatchNorm"
  bottom: "resx1_conv1"
  top: "resx1_conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv1_scale"
  type: "Scale"
  bottom: "resx1_conv1"
  top: "resx1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv1_relu"
  type: "ReLU"
  bottom: "resx1_conv1"
  top: "resx1_conv1"
}
##############
layer {
  name: "permute1"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute1"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_1"
  type: "Convolution"
  bottom: "permute1"
  top: "resx1_conv2_1"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_1_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_1"
  top: "resx1_conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_1_scale"
  type: "Scale"
  bottom: "resx1_conv2_1"
  top: "resx1_conv2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_1_relu"
  type: "ReLU"
  bottom: "resx1_conv2_1"
  top: "resx1_conv2_1"
}
layer {
  name: "permute2"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute2"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_2"
  type: "Convolution"
  bottom: "permute2"
  top: "resx1_conv2_2"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_2_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_2"
  top: "resx1_conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_2_scale"
  type: "Scale"
  bottom: "resx1_conv2_2"
  top: "resx1_conv2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_2_relu"
  type: "ReLU"
  bottom: "resx1_conv2_2"
  top: "resx1_conv2_2"
}
layer {
  name: "permute3"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute3"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_3"
  type: "Convolution"
  bottom: "permute3"
  top: "resx1_conv2_3"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_3_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_3"
  top: "resx1_conv2_3"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_3_scale"
  type: "Scale"
  bottom: "resx1_conv2_3"
  top: "resx1_conv2_3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_3_relu"
  type: "ReLU"
  bottom: "resx1_conv2_3"
  top: "resx1_conv2_3"
}
layer {
  name: "permute4"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute4"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_4"
  type: "Convolution"
  bottom: "permute4"
  top: "resx1_conv2_4"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_4_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_4"
  top: "resx1_conv2_4"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_4_scale"
  type: "Scale"
  bottom: "resx1_conv2_4"
  top: "resx1_conv2_4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_4_relu"
  type: "ReLU"
  bottom: "resx1_conv2_4"
  top: "resx1_conv2_4"
}
layer {
  name: "permute5"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute5"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_5"
  type: "Convolution"
  bottom: "permute5"
  top: "resx1_conv2_5"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_5_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_5"
  top: "resx1_conv2_5"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_5_scale"
  type: "Scale"
  bottom: "resx1_conv2_5"
  top: "resx1_conv2_5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_5_relu"
  type: "ReLU"
  bottom: "resx1_conv2_5"
  top: "resx1_conv2_5"
}
layer {
  name: "permute6"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute6"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_6"
  type: "Convolution"
  bottom: "permute6"
  top: "resx1_conv2_6"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_6_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_6"
  top: "resx1_conv2_6"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_6_scale"
  type: "Scale"
  bottom: "resx1_conv2_6"
  top: "resx1_conv2_6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_6_relu"
  type: "ReLU"
  bottom: "resx1_conv2_6"
  top: "resx1_conv2_6"
}
layer {
  name: "permute7"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute7"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_7"
  type: "Convolution"
  bottom: "permute7"
  top: "resx1_conv2_7"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_7_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_7"
  top: "resx1_conv2_7"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_7_scale"
  type: "Scale"
  bottom: "resx1_conv2_7"
  top: "resx1_conv2_7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_7_relu"
  type: "ReLU"
  bottom: "resx1_conv2_7"
  top: "resx1_conv2_7"
}
layer {
  name: "permute8"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute8"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_8"
  type: "Convolution"
  bottom: "permute8"
  top: "resx1_conv2_8"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_8_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_8"
  top: "resx1_conv2_8"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_8_scale"
  type: "Scale"
  bottom: "resx1_conv2_8"
  top: "resx1_conv2_8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_8_relu"
  type: "ReLU"
  bottom: "resx1_conv2_8"
  top: "resx1_conv2_8"
}
layer {
  name: "permute9"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute9"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_9"
  type: "Convolution"
  bottom: "permute9"
  top: "resx1_conv2_9"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_9_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_9"
  top: "resx1_conv2_9"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_9_scale"
  type: "Scale"
  bottom: "resx1_conv2_9"
  top: "resx1_conv2_9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_9_relu"
  type: "ReLU"
  bottom: "resx1_conv2_9"
  top: "resx1_conv2_9"
}
layer {
  name: "permute10"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute10"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_10"
  type: "Convolution"
  bottom: "permute10"
  top: "resx1_conv2_10"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_10_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_10"
  top: "resx1_conv2_10"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_10_scale"
  type: "Scale"
  bottom: "resx1_conv2_10"
  top: "resx1_conv2_10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_10_relu"
  type: "ReLU"
  bottom: "resx1_conv2_10"
  top: "resx1_conv2_10"
}
layer {
  name: "permute11"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute11"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_11"
  type: "Convolution"
  bottom: "permute11"
  top: "resx1_conv2_11"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_11_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_11"
  top: "resx1_conv2_11"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_11_scale"
  type: "Scale"
  bottom: "resx1_conv2_11"
  top: "resx1_conv2_11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_11_relu"
  type: "ReLU"
  bottom: "resx1_conv2_11"
  top: "resx1_conv2_11"
}
layer {
  name: "permute12"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute12"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_12"
  type: "Convolution"
  bottom: "permute12"
  top: "resx1_conv2_12"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_12_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_12"
  top: "resx1_conv2_12"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_12_scale"
  type: "Scale"
  bottom: "resx1_conv2_12"
  top: "resx1_conv2_12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_12_relu"
  type: "ReLU"
  bottom: "resx1_conv2_12"
  top: "resx1_conv2_12"
}
layer {
  name: "permute13"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute13"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_13"
  type: "Convolution"
  bottom: "permute13"
  top: "resx1_conv2_13"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_13_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_13"
  top: "resx1_conv2_13"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_13_scale"
  type: "Scale"
  bottom: "resx1_conv2_13"
  top: "resx1_conv2_13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_13_relu"
  type: "ReLU"
  bottom: "resx1_conv2_13"
  top: "resx1_conv2_13"
}
layer {
  name: "permute14"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute14"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_14"
  type: "Convolution"
  bottom: "permute14"
  top: "resx1_conv2_14"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_14_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_14"
  top: "resx1_conv2_14"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_14_scale"
  type: "Scale"
  bottom: "resx1_conv2_14"
  top: "resx1_conv2_14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_14_relu"
  type: "ReLU"
  bottom: "resx1_conv2_14"
  top: "resx1_conv2_14"
}
layer {
  name: "permute15"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute15"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_15"
  type: "Convolution"
  bottom: "permute15"
  top: "resx1_conv2_15"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_15_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_15"
  top: "resx1_conv2_15"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_15_scale"
  type: "Scale"
  bottom: "resx1_conv2_15"
  top: "resx1_conv2_15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_15_relu"
  type: "ReLU"
  bottom: "resx1_conv2_15"
  top: "resx1_conv2_15"
}
layer {
  name: "permute16"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute16"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_16"
  type: "Convolution"
  bottom: "permute16"
  top: "resx1_conv2_16"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_16_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_16"
  top: "resx1_conv2_16"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_16_scale"
  type: "Scale"
  bottom: "resx1_conv2_16"
  top: "resx1_conv2_16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_16_relu"
  type: "ReLU"
  bottom: "resx1_conv2_16"
  top: "resx1_conv2_16"
}
layer {
  name: "permute17"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute17"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_17"
  type: "Convolution"
  bottom: "permute17"
  top: "resx1_conv2_17"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_17_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_17"
  top: "resx1_conv2_17"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_17_scale"
  type: "Scale"
  bottom: "resx1_conv2_17"
  top: "resx1_conv2_17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_17_relu"
  type: "ReLU"
  bottom: "resx1_conv2_17"
  top: "resx1_conv2_17"
}
layer {
  name: "permute18"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute18"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_18"
  type: "Convolution"
  bottom: "permute18"
  top: "resx1_conv2_18"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_18_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_18"
  top: "resx1_conv2_18"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_18_scale"
  type: "Scale"
  bottom: "resx1_conv2_18"
  top: "resx1_conv2_18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_18_relu"
  type: "ReLU"
  bottom: "resx1_conv2_18"
  top: "resx1_conv2_18"
}
layer {
  name: "permute19"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute19"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_19"
  type: "Convolution"
  bottom: "permute19"
  top: "resx1_conv2_19"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_19_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_19"
  top: "resx1_conv2_19"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_19_scale"
  type: "Scale"
  bottom: "resx1_conv2_19"
  top: "resx1_conv2_19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_19_relu"
  type: "ReLU"
  bottom: "resx1_conv2_19"
  top: "resx1_conv2_19"
}
layer {
  name: "permute20"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute20"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_20"
  type: "Convolution"
  bottom: "permute20"
  top: "resx1_conv2_20"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_20_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_20"
  top: "resx1_conv2_20"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_20_scale"
  type: "Scale"
  bottom: "resx1_conv2_20"
  top: "resx1_conv2_20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_20_relu"
  type: "ReLU"
  bottom: "resx1_conv2_20"
  top: "resx1_conv2_20"
}
layer {
  name: "permute21"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute21"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_21"
  type: "Convolution"
  bottom: "permute21"
  top: "resx1_conv2_21"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_21_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_21"
  top: "resx1_conv2_21"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_21_scale"
  type: "Scale"
  bottom: "resx1_conv2_21"
  top: "resx1_conv2_21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_21_relu"
  type: "ReLU"
  bottom: "resx1_conv2_21"
  top: "resx1_conv2_21"
}
layer {
  name: "permute22"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute22"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_22"
  type: "Convolution"
  bottom: "permute22"
  top: "resx1_conv2_22"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_22_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_22"
  top: "resx1_conv2_22"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_22_scale"
  type: "Scale"
  bottom: "resx1_conv2_22"
  top: "resx1_conv2_22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_22_relu"
  type: "ReLU"
  bottom: "resx1_conv2_22"
  top: "resx1_conv2_22"
}
layer {
  name: "permute23"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute23"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_23"
  type: "Convolution"
  bottom: "permute23"
  top: "resx1_conv2_23"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_23_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_23"
  top: "resx1_conv2_23"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_23_scale"
  type: "Scale"
  bottom: "resx1_conv2_23"
  top: "resx1_conv2_23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_23_relu"
  type: "ReLU"
  bottom: "resx1_conv2_23"
  top: "resx1_conv2_23"
}
layer {
  name: "permute24"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute24"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_24"
  type: "Convolution"
  bottom: "permute24"
  top: "resx1_conv2_24"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_24_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_24"
  top: "resx1_conv2_24"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_24_scale"
  type: "Scale"
  bottom: "resx1_conv2_24"
  top: "resx1_conv2_24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_24_relu"
  type: "ReLU"
  bottom: "resx1_conv2_24"
  top: "resx1_conv2_24"
}
layer {
  name: "permute25"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute25"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_25"
  type: "Convolution"
  bottom: "permute25"
  top: "resx1_conv2_25"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_25_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_25"
  top: "resx1_conv2_25"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_25_scale"
  type: "Scale"
  bottom: "resx1_conv2_25"
  top: "resx1_conv2_25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_25_relu"
  type: "ReLU"
  bottom: "resx1_conv2_25"
  top: "resx1_conv2_25"
}
layer {
  name: "permute26"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute26"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_26"
  type: "Convolution"
  bottom: "permute26"
  top: "resx1_conv2_26"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_26_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_26"
  top: "resx1_conv2_26"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_26_scale"
  type: "Scale"
  bottom: "resx1_conv2_26"
  top: "resx1_conv2_26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_26_relu"
  type: "ReLU"
  bottom: "resx1_conv2_26"
  top: "resx1_conv2_26"
}
layer {
  name: "permute27"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute27"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_27"
  type: "Convolution"
  bottom: "permute27"
  top: "resx1_conv2_27"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_27_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_27"
  top: "resx1_conv2_27"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_27_scale"
  type: "Scale"
  bottom: "resx1_conv2_27"
  top: "resx1_conv2_27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_27_relu"
  type: "ReLU"
  bottom: "resx1_conv2_27"
  top: "resx1_conv2_27"
}
layer {
  name: "permute28"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute28"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_28"
  type: "Convolution"
  bottom: "permute28"
  top: "resx1_conv2_28"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_28_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_28"
  top: "resx1_conv2_28"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_28_scale"
  type: "Scale"
  bottom: "resx1_conv2_28"
  top: "resx1_conv2_28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_28_relu"
  type: "ReLU"
  bottom: "resx1_conv2_28"
  top: "resx1_conv2_28"
}
layer {
  name: "permute29"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute29"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_29"
  type: "Convolution"
  bottom: "permute29"
  top: "resx1_conv2_29"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_29_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_29"
  top: "resx1_conv2_29"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_29_scale"
  type: "Scale"
  bottom: "resx1_conv2_29"
  top: "resx1_conv2_29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_29_relu"
  type: "ReLU"
  bottom: "resx1_conv2_29"
  top: "resx1_conv2_29"
}
layer {
  name: "permute30"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute30"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_30"
  type: "Convolution"
  bottom: "permute30"
  top: "resx1_conv2_30"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_30_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_30"
  top: "resx1_conv2_30"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_30_scale"
  type: "Scale"
  bottom: "resx1_conv2_30"
  top: "resx1_conv2_30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_30_relu"
  type: "ReLU"
  bottom: "resx1_conv2_30"
  top: "resx1_conv2_30"
}
layer {
  name: "permute31"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute31"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_31"
  type: "Convolution"
  bottom: "permute31"
  top: "resx1_conv2_31"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_31_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_31"
  top: "resx1_conv2_31"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_31_scale"
  type: "Scale"
  bottom: "resx1_conv2_31"
  top: "resx1_conv2_31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_31_relu"
  type: "ReLU"
  bottom: "resx1_conv2_31"
  top: "resx1_conv2_31"
}
layer {
  name: "permute32"
  type: "Permute"
  bottom: "resx1_conv1"
  top: "permute32"
  permute_param {
    # order: 0
    # order: 2
    # order: 3
    # order: 1
  }
}
layer {
  name: "resx1_conv2_32"
  type: "Convolution"
  bottom: "permute32"
  top: "resx1_conv2_32"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    # group: 32
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -14
    scale: 1.1123641
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.0864162
  }
}
layer {
  name: "resx1_conv2_32_bn"
  type: "BatchNorm"
  bottom: "resx1_conv2_32"
  top: "resx1_conv2_32"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv2_32_scale"
  type: "Scale"
  bottom: "resx1_conv2_32"
  top: "resx1_conv2_32"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_conv2_32_relu"
  type: "ReLU"
  bottom: "resx1_conv2_32"
  top: "resx1_conv2_32"
}
layer {
  name: "concat1"
  type: "Concat"
  bottom: "resx1_conv2_1"
  bottom: "resx1_conv2_2"
  bottom: "resx1_conv2_3"
  bottom: "resx1_conv2_4"
  bottom: "resx1_conv2_5"
  bottom: "resx1_conv2_6"
  bottom: "resx1_conv2_7"
  bottom: "resx1_conv2_8"
  bottom: "resx1_conv2_9"
  bottom: "resx1_conv2_10"
  bottom: "resx1_conv2_11"
  bottom: "resx1_conv2_12"
  bottom: "resx1_conv2_13"
  bottom: "resx1_conv2_14"
  bottom: "resx1_conv2_15"
  bottom: "resx1_conv2_16"
  bottom: "resx1_conv2_17"
  bottom: "resx1_conv2_18"
  bottom: "resx1_conv2_19"
  bottom: "resx1_conv2_20"
  bottom: "resx1_conv2_21"
  bottom: "resx1_conv2_22"
  bottom: "resx1_conv2_23"
  bottom: "resx1_conv2_24"
  bottom: "resx1_conv2_25"
  bottom: "resx1_conv2_26"
  bottom: "resx1_conv2_27"
  bottom: "resx1_conv2_28"
  bottom: "resx1_conv2_29"
  bottom: "resx1_conv2_30"
  bottom: "resx1_conv2_31"
  bottom: "resx1_conv2_32"
  top: "concat1"
}

##################
layer {
  name: "resx1_conv3"
  type: "Convolution"
  bottom: "concat1"
  top: "resx1_conv3"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -13
    scale: 1.5067966
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.1504707
  }
}
layer {
  name: "resx1_conv3_bn"
  type: "BatchNorm"
  bottom: "resx1_conv3"
  top: "resx1_conv3"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_conv3_scale"
  type: "Scale"
  bottom: "resx1_conv3"
  top: "resx1_conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_match_conv"
  type: "Convolution"
  bottom: "data"
  top: "resx1_match_conv"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
  bottom_mlu_dtype {
    type: DT_INT16
    position: -12
    scale: 1.813458
  }
  blobs_dtype {
    type: DT_INT16
    position: -15
    scale: 1.6565351
  }
}
layer {
  name: "resx1_match_conv_bn"
  type: "BatchNorm"
  bottom: "resx1_match_conv"
  top: "resx1_match_conv"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "resx1_match_conv_scale"
  type: "Scale"
  bottom: "resx1_match_conv"
  top: "resx1_match_conv"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx1_elewise"
  type: "Eltwise"
  bottom: "resx1_match_conv"
  bottom: "resx1_conv3"
  top: "resx1_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resx1_elewise_relu"
  type: "ReLU"
  bottom: "resx1_elewise"
  top: "resx1_elewise"
}
